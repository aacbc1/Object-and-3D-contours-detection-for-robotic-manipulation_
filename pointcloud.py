# -*- coding: utf-8 -*-
"""PointCloud.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xqoXFare6LDCI12JH3W2Gw6gGXr51n04
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import json
from matplotlib.patches import FancyArrowPatch
from mpl_toolkits.mplot3d import proj3d

def area(box):
    x1, y1, x2, y2 = box
    return (x2 - x1) * (y2 - y1)

def is_inside(inner, outer):
    x1, y1, x2, y2 = inner
    X1, Y1, X2, Y2 = outer
    if y1>y2:
      g_y = y1
      g_x = x1
      d_y = y2
      d_x = x2
    else:
      g_y = y2
      g_x = x2
      d_y = y1
      d_x = x1
    if Y1>Y2:
      G_Y = Y1
      G_X = X1
      D_Y = Y2
      D_X = X2
    else:
      G_Y = Y2
      G_X = X2
      D_Y = Y1
      D_X = X1

    pom = 0
    if (d_x>D_X and d_y>D_X and g_x<G_X and g_y<G_Y) or  (d_x<D_X and d_y<D_X and g_x>G_X and g_y>G_Y):
      pom = 1
    return pom

def is_inside_point(bounding_box, point):
    if not bounding_box or len(bounding_box[0]) != 4:
        return False
    x1, y1, x2, y2 = bounding_box[0]
    X1, Y1 = point
    pom = 0
    if (X1>=x1 and Y1>=y1 and X1<=x2 and Y1<=y2):
      pom = 1

    return pom

def CannyDetection(img):
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  blurred = cv2.GaussianBlur(gray, (1,1), 2.5)

  _, thresholded = cv2.threshold(blurred, 80, 255, cv2.THRESH_TOZERO)

  edges = cv2.Canny(thresholded, 50, 300)

  kernel = np.ones((27,27), np.uint8)

  edges_dilated = cv2.dilate(edges, kernel, iterations=2)

  edges_closed = cv2.morphologyEx(edges_dilated, cv2.MORPH_CLOSE, kernel)

  contours, hierarchy = cv2.findContours(edges_closed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

  return contours,blurred,edges

def removeRed(img):
  hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

  lower_red1 = np.array([0, 50, 50])
  upper_red1 = np.array([10, 255, 255])
  mask1 = cv2.inRange(hsv, lower_red1, upper_red1)

  lower_red2 = np.array([170, 50, 50])
  upper_red2 = np.array([180, 255, 255])
  mask2 = cv2.inRange(hsv, lower_red2, upper_red2)

  red_mask = cv2.bitwise_or(mask1, mask2)

  mask_inv = cv2.bitwise_not(red_mask)
  img_no_red = cv2.bitwise_and(img, img, mask=mask_inv)
  return img_no_red

def BoundingBox(img,contours):
  h, w = img.shape[:2]
  bounding_boxes = []

  for i, cnt in enumerate(contours):
    x, y, w_box, h_box = cv2.boundingRect(cnt)

    if w_box > 0.8 * w or h_box > 0.8 * h:
        continue

    if w_box * h_box < 5000:
        continue
    if w_box * h_box > 160000:
        continue
    aspect_ratio = max(w_box / h_box, h_box / w_box)
    if aspect_ratio > 6:
        continue

    x_new = max(x, 0)
    y_new = max(y, 0)
    x_end = min(x + w_box, w)
    y_end = min(y + h_box, h)
    bounding_boxes.append((x_new, y_new, x_end, y_end))

    return  bounding_boxes

def show(img,blurred,final_boxes,edges):

  output = img.copy()


  cropped_objects = []

  for x1, y1, x2, y2 in final_boxes:
    cv2.rectangle(output, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cropped = img[y1:y2, x1:x2]
    cropped_objects.append(cropped)

  plt.figure(figsize=(10, 6))
  plt.subplot(1, 3, 1)
  plt.imshow(blurred, cmap='gray')
  plt.axis('off')
  plt.title('Blurred')

  plt.subplot(1, 3, 2)
  plt.imshow(edges, cmap='gray')
  plt.axis('off')
  plt.title('Edges')
  plt.subplot(1, 3, 3)
  plt.imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))
  plt.axis('off')
  plt.title('Detected Objects')
  plt.show()

  num_objects = len(cropped_objects)
  cols = 4
  rows = (num_objects + cols - 1) // cols

  plt.figure(figsize=(15, 4 * rows))
  for i, obj in enumerate(cropped_objects):
    plt.subplot(rows, cols, i + 1)
    plt.imshow(cv2.cvtColor(obj, cv2.COLOR_BGR2RGB))
    plt.title(f"Object {i + 1}")
    plt.axis('off')

  plt.tight_layout()
  plt.show()

def filterBoundingBox(bounding_boxes):
  sorted_boxes = sorted(enumerate(bounding_boxes), key=lambda x: area(x[1]), reverse=True)
  kept_indices = set()
  removed_indices = set()

  for i, (idx_i, box_i) in enumerate(sorted_boxes):
    if idx_i in removed_indices:
      continue
    kept_indices.add(idx_i)
    for j in range(i + 1, len(sorted_boxes)):
        idx_j, box_j = sorted_boxes[j]
        if is_inside(box_j, box_i):
            removed_indices.add(idx_j)

  final_boxes = [bounding_boxes[i] for i in kept_indices]
  return final_boxes

def K(file):

  K1 = None
  dist = None
  camera = json.load(file)
  focal_length = camera['focal_length']
  fx1 = camera['fx']
  fy1 = camera['fy']
  resolution = camera['resolution']  # (width, height)

  cx1 = resolution['width'] / 2
  cy1 = resolution['height'] / 2

  K1 = np.array([
        [fx1, 0, cx1],
        [0, fy1, cy1],
        [0, 0, 1]
    ], dtype=np.float64)


  dist = np.zeros((5, 1))
  return K1

#with open(r'0_camera_params.json') as file:
#  K = K(file)
#print(K)

fx = fy = 3550.0
cx = 2016.0
cy = 1512.0

K = np.array([
    [fx,  0, cx],
    [ 0, fy, cy],
    [ 0,  0,  1]
])

def disparity(img1, img2, bounding_box_1, bounding_box_2):
    sift = cv2.SIFT_create( nOctaveLayers=6, contrastThreshold=0.001,
                edgeThreshold=0.01, sigma=1.5)
    #nfeatures=10000
    #sift = cv2.SIFT_create()




    kp1, des1 = sift.detectAndCompute(img1, None)
    kp2, des2 = sift.detectAndCompute(img2, None)



    kp1_filtered = []
    des1_filtered = []
    for kp, desc in zip(kp1, des1):
      pom = np.array(kp.pt, dtype=np.float32)
      temp = is_inside_point(bounding_box_1, pom)
      if is_inside_point(bounding_box_1, pom):
        kp1_filtered.append(kp)
        des1_filtered.append(desc)
    kp2_filtered = []
    des2_filtered = []
    for kp, desc in zip(kp2, des2):
      pom = np.array(kp.pt, dtype=np.float32)
      if is_inside_point(bounding_box_2, pom):
        kp2_filtered.append(kp)
        des2_filtered.append(desc)

    if len(kp1_filtered) < 2 or len(kp2_filtered) < 2:
        print("Nedovoljno ta훾aka unutar bounding boxova.")
        return [], None, None

    des1_filtered = np.array(des1_filtered)
    des2_filtered = np.array(des2_filtered)

    bf = cv2.BFMatcher(cv2.NORM_L2)
    matches = bf.knnMatch(des1_filtered, des2_filtered, k=2)
    good_matches = []
    for m, n in matches:
        if m.distance < 0.85 * n.distance:
            good_matches.append(m)



    src_pts = np.float32([kp1_filtered[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp2_filtered[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)


    F, mask = cv2.findFundamentalMat(src_pts, dst_pts, cv2.FM_RANSAC)
    src_pts = src_pts[mask.ravel() == 1]
    dst_pts = dst_pts[mask.ravel() == 1]

    matched_key_list = [[kp1_filtered[m.queryIdx].pt, kp2_filtered[m.trainIdx].pt] for m in good_matches if mask is not None and mask[good_matches.index(m)]]
    img_matches = cv2.drawMatches(
        img1, kp1_filtered,
        img2, kp2_filtered,
        [m for i, m in enumerate(good_matches) if mask[i]],
        None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS
    )
    plt.figure(figsize=(15, 10))
    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))
    plt.title("Matches")
    plt.axis("off")
    plt.show()

    return matched_key_list, src_pts, dst_pts

def disparity(img1, img2):

    sift = cv2.SIFT_create(contrastThreshold = 0.1)



    kp1, des1 = sift.detectAndCompute(img1, None)
    kp2, des2 = sift.detectAndCompute(img2, None)


    des1 = np.array(des1)
    des2 = np.array(des2)

    bf = cv2.BFMatcher(cv2.NORM_L2)
    matches = bf.knnMatch(des1, des2, k=2)
    good_matches = []
    for m, n in matches:
        if m.distance < 0.85 * n.distance:
            good_matches.append(m)

    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)


    F, mask = cv2.findFundamentalMat(src_pts, dst_pts, cv2.FM_RANSAC, 3, 0.99)
    src_pts = src_pts[mask.ravel() == 1]
    dst_pts = dst_pts[mask.ravel() == 1]


    matched_key_list = [[kp1[m.queryIdx].pt, kp2[m.trainIdx].pt] for m in good_matches if mask is not None and mask[good_matches.index(m)]]
    img_matches = cv2.drawMatches(
        img1, kp1,
        img2, kp2,
        [m for i, m in enumerate(good_matches) if mask[i]],
        None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS
    )
    plt.figure(figsize=(15, 10))
    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))
    plt.title("Matches")
    plt.axis("off")
    plt.show()

    return matched_key_list, src_pts, dst_pts

def points_3D(img1,img2):

  img_no_red1 = removeRed(img1)
  contours1,blurred1,edges1 = CannyDetection(img_no_red1)
  bounding_boxes1 = BoundingBox(img1,contours1)
  final_boxes1 = filterBoundingBox(bounding_boxes1)

  img_no_red2 = removeRed(img2)
  contours2,blurred2,edges2 = CannyDetection(img_no_red2)
  bounding_boxes2 = BoundingBox(img2,contours2)
  final_boxes2 = filterBoundingBox(bounding_boxes2)
  if not final_boxes1 or not final_boxes2:
    return None

  #show(img1,blurred1,final_boxes1,edges1)
  #show(img2,blurred2,final_boxes2,edges2)

  _, src_pts, dst_pts  = disparity(img1,img2, final_boxes1, final_boxes2)
  #print(np.shape(src_pts))
  #print(np.shape(dst_pts))
  p1 = src_pts[:, 0, :]
  p2 = dst_pts[:, 0, :]

  #p1 = np.r_[p1, np.ones((1, p1.shape[1]))]
  #p2 = np.r_[p2, np.ones((1, p2.shape[1]))]

  E, mask = cv2.findEssentialMat(
    p1,
    p2,
    cameraMatrix=K,
    method=cv2.RANSAC,
    prob=0.999,
    threshold=1.0
)

  #E = estimateEssentialMatrix(p1, p2, K1, K1);
  #Rots, u3 = decomposeEssentialMatrix(E)
  R1, R2, u3 = cv2.decomposeEssentialMat(E)
  Rots = np.stack((R1, R2), axis=2)
  print(np.shape(p1))
  retval, R, t, mask = cv2.recoverPose(E, p1, p2, K)

  #R_C2_W,T_C2_W = disambiguateRelativePose(Rots, u3, p1, p2, K, K)

  M1 = K @ np.eye(3,4)
  M2 = K @ np.c_[R, t]
  #P = linearTriangulation(p1, p2, M1, M2)
  points_4d_hom = cv2.triangulatePoints(M1, M2, p1.T, p2.T)
  print(np.shape(p1.T))
  P = points_4d_hom[:3] / points_4d_hom[3]

  return P

def points_3D(img1,img2):


  _, src_pts, dst_pts  = disparity(img1,img2)

  p1 = src_pts[:, 0, :]
  p2 = dst_pts[:, 0, :]



  E, mask = cv2.findEssentialMat(
    p1,
    p2,
    cameraMatrix=K,
    method=cv2.RANSAC,
    prob=0.999,
    threshold=1.0
)


  R1, R2, u3 = cv2.decomposeEssentialMat(E)
  Rots = np.stack((R1, R2), axis=2)
  retval, R, t, mask = cv2.recoverPose(E, p1, p2, K)


  M1 = K @ np.eye(3,4)
  M2 = K @ np.c_[R, t]

  points_4d_hom = cv2.triangulatePoints(M1, M2, p1.T, p2.T)
  P = points_4d_hom[:3] / points_4d_hom[3]


  return P,M2

def showPointCloud(P):
  fig = plt.figure()
  ax = fig.add_subplot(111, projection='3d')
  ax.scatter(P[0,:], P[1,:], color = 'y', marker='s')
  ax.set_title("3D oblak ta훾aka")
  ax.set_xlabel("X")
  ax.set_ylabel("Y")
  ax.set_zlabel("Z")
  plt.show()

img1 = cv2.imread('img1.JPG')
img2 = cv2.imread('img2.JPG')
img3 = cv2.imread('img5.JPG')
img4 = cv2.imread('img6.JPG')
img5 = cv2.imread('img7.JPG')
img6 = cv2.imread('5_rgb.png')
img7 = cv2.imread('6_rgb.png')
img8 = cv2.imread('7_rgb.png')
img9 = cv2.imread('8_rgb.png')

imgs = [img2,img3,img4,img5]
point_clouds = []
P,M2 = points_3D(img1, img2)
point_clouds.append(P[:, :])

sift = cv2.SIFT_create()

kp3, des3 = sift.detectAndCompute(img3, None)
kp1, des1 = sift.detectAndCompute(img1, None)
kp2, des2 = sift.detectAndCompute(img2, None)
bf = cv2.BFMatcher(cv2.NORM_L2)
matches13 = bf.knnMatch(des3, des1, k=2)
matches23 = bf.knnMatch(des3, des2, k=2)
_, src_pts, dst_pts  = disparity(img1,img2)
good_matches13 = [m for m, n in matches13 if m.distance < 0.8 * n.distance]
good_matches23 = [m for m, n in matches23 if m.distance < 0.8 * n.distance]

threshold = 3

object_points = []
image_points  = []

for m in good_matches13:
    pt_img1 = kp1[m.trainIdx].pt
    pt_img3 = kp3[m.queryIdx].pt

    for i, src_pt in enumerate(src_pts.reshape(-1, 2)):
        dist = np.linalg.norm(np.array(pt_img1) - src_pt)
        if dist < threshold:
            object_points.append(P[:, i])
            image_points.append(pt_img3)
            break

for m in good_matches23:
    pt_img2 = kp2[m.trainIdx].pt
    pt_img3 = kp3[m.queryIdx].pt

    for i, dst_pt in enumerate(dst_pts.reshape(-1, 2)):
        dist = np.linalg.norm(np.array(pt_img2) - dst_pt)
        if dist < threshold:
            object_points.append(P[:, i])
            image_points.append(pt_img3)
            break

object_points = np.array(object_points, dtype=np.float32).reshape(-1, 3)
image_points  = np.array(image_points, dtype=np.float32).reshape(-1, 2)

success, rvec, tvec = cv2.solvePnP(object_points, image_points, K, None)
if not success:
    print("-")
else:
    R, _ = cv2.Rodrigues(rvec)

M3 = K @ np.hstack((R, tvec))

import numpy as np
import matplotlib.pyplot as plt

M1 = K @ np.hstack((np.eye(3), np.zeros((3,1))))
M3 = K @ np.hstack((R, tvec))
def remove_outliers_reprojection(K, R, tvec, pts_3d, pts_2d, threshold=3.0):

    rvec, _ = cv2.Rodrigues(R)
    proj_pts, _ = cv2.projectPoints(pts_3d.reshape(-1, 1, 3), rvec, tvec, K, None)
    proj_pts = proj_pts.reshape(-1, 2)

    errors = np.linalg.norm(proj_pts - pts_2d, axis=1)
    mask = errors < threshold
    return pts_3d[mask], mask

def get_new_correspondences(kpA, kpB, desA, desB, existing_pts_2d, threshold=3):
    bf = cv2.BFMatcher(cv2.NORM_L2)
    matches = bf.knnMatch(desA, desB, k=2)
    good_matches = [m for m,n in matches if m.distance < 0.8 * n.distance]

    ptsA = []
    ptsB = []

    for m in good_matches:
        ptA = np.array(kpA[m.queryIdx].pt)
        ptB = np.array(kpB[m.trainIdx].pt)

        dist_to_existing = np.min(np.linalg.norm(existing_pts_2d - ptA, axis=1)) if len(existing_pts_2d) > 0 else np.inf
        if dist_to_existing > threshold:
            ptsA.append(ptA)
            ptsB.append(ptB)
    return np.array(ptsA), np.array(ptsB)

existing_pts_img1 = src_pts.reshape(-1,2)
existing_pts_img2 = dst_pts.reshape(-1,2)

pts_img1_new, pts_img3_1 = get_new_correspondences(kp1, kp3, des1, des3, existing_pts_img1)
pts_img2_new, pts_img3_2 = get_new_correspondences(kp2, kp3, des2, des3, existing_pts_img2)


points_4d_1 = cv2.triangulatePoints(M1, M3, pts_img1_new.T, pts_img3_1.T)
points_3d_1 = points_4d_1[:3] / points_4d_1[3]

points_4d_2 = cv2.triangulatePoints(M2, M3, pts_img2_new.T, pts_img3_2.T)
points_3d_2 = points_4d_2[:3] / points_4d_2[3]

#points_3d_1_filtered, mask1 = remove_outliers_reprojection(K, np.eye(3), np.zeros(3), points_3d_1.T, pts_img1_new)
#pts_img3_1_filtered = pts_img3_1[mask1]

#points_3d_2_filtered, mask2 = remove_outliers_reprojection(K, R, tvec, points_3d_2.T, pts_img2_new)
#pts_img3_2_filtered = pts_img3_2[mask2]

#P_all_new = np.hstack((points_3d_1_filtered.T, points_3d_2_filtered.T))

P_all_new = np.hstack((points_3d_1, points_3d_2))

P_total = np.hstack((P, P_all_new))

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(P_total[0], P_total[1], P_total[2], c='r', marker='o', s=1)
ax.set_title('3D Point Cloud')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()

def filter_by_depth(P_cam):
  return P_cam[:, P_cam[2, :] > 0]
P_total = filter_by_depth(P_total)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(P_total[0], P_total[1], P_total[2], c='r', marker='o', s=1)
ax.set_title('3D Point Cloud')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()
Z = P_total[2]

count_z_gt_1000     = np.sum(Z > 1000)
count_z_100_1000    = np.sum((Z > 100) & (Z <= 1000))
count_z_10_100      = np.sum((Z > 10) & (Z <= 100))
count_z_0_10        = np.sum((Z > 0) & (Z <= 10))

N_total = Z.shape[0]

print("Z > 1000       : {:.2f}%".format(100 * np.sum(Z > 1000) / N_total))
print("100 < Z <= 1000: {:.2f}%".format(100 * np.sum((Z > 100) & (Z <= 1000)) / N_total))
print("10 < Z <= 100  : {:.2f}%".format(100 * np.sum((Z > 10) & (Z <= 100)) / N_total))
print("0 < Z <= 10    : {:.2f}%".format(100 * np.sum((Z > 0) & (Z <= 10)) / N_total))
print("Z <= 0         : {:.2f}%".format(100 * np.sum(Z <= 0) / N_total))  # 훾esto su i to outlieri


z_threshold = 10.0

mask = P_total[2] < z_threshold

P_total_filtered = P_total[:, mask]
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(P_total_filtered[0], P_total_filtered[1], P_total_filtered[2], c='r', marker='o', s=1)
ax.set_title('3D Point Cloud')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()

kp4, des4 = sift.detectAndCompute(img4, None)

matches14 = bf.knnMatch(des4, des1, k=2)
matches24 = bf.knnMatch(des4, des2, k=2)
matches34 = bf.knnMatch(des4, des3, k=2)

good_matches14 = [m for m, n in matches14 if m.distance < 0.8 * n.distance]
good_matches24 = [m for m, n in matches24 if m.distance < 0.8 * n.distance]
good_matches34 = [m for m, n in matches34 if m.distance < 0.8 * n.distance]

object_points = []
image_points  = []
threshold = 3

for m in good_matches14:
    pt_img1 = kp1[m.trainIdx].pt
    pt_img4 = kp4[m.queryIdx].pt

    for i, src_pt in enumerate(src_pts.reshape(-1, 2)):
        dist = np.linalg.norm(np.array(pt_img1) - src_pt)
        if dist < threshold:
            object_points.append(P[:, i])
            image_points.append(pt_img4)
            break

for m in good_matches24:
    pt_img2 = kp2[m.trainIdx].pt
    pt_img4 = kp4[m.queryIdx].pt

    for i, dst_pt in enumerate(dst_pts.reshape(-1, 2)):
        dist = np.linalg.norm(np.array(pt_img2) - dst_pt)
        if dist < threshold:
            object_points.append(P[:, i])
            image_points.append(pt_img4)
            break

existing_pts_3d    = np.hstack((points_3d_1, points_3d_2))
existing_pts_img3 = np.vstack((pts_img3_1, pts_img3_2))
for m in good_matches34:
    pt_img3 = kp3[m.trainIdx].pt
    pt_img4 = kp4[m.queryIdx].pt

    for i, pt in enumerate(existing_pts_img3.reshape(-1, 2)):
        dist = np.linalg.norm(np.array(pt_img3) - pt)
        if dist < threshold:
            object_points.append(existing_pts_3d[:, i])
            image_points.append(pt_img4)
            break

object_points = np.array(object_points, dtype=np.float32).reshape(-1, 3)
image_points  = np.array(image_points, dtype=np.float32).reshape(-1, 2)

success, rvec4, tvec4 = cv2.solvePnP(object_points, image_points, K, None)
if not success:
    print("-")
else:
    R4, _ = cv2.Rodrigues(rvec4)
    M4 = K @ np.hstack((R4, tvec4))


pts_img1_new_4, pts_img4_1 = get_new_correspondences(kp1, kp4, des1, des4, src_pts.reshape(-1,2))
pts_img2_new_4, pts_img4_2 = get_new_correspondences(kp2, kp4, des2, des4, dst_pts.reshape(-1,2))
pts_img3_new_4, pts_img4_3 = get_new_correspondences(kp3, kp4, des3, des4, existing_pts_img3)

points_4d_1_4 = cv2.triangulatePoints(M1, M4, pts_img1_new_4.T, pts_img4_1.T)
points_3d_1_4 = points_4d_1_4[:3] / points_4d_1_4[3]

points_4d_2_4 = cv2.triangulatePoints(M2, M4, pts_img2_new_4.T, pts_img4_2.T)
points_3d_2_4 = points_4d_2_4[:3] / points_4d_2_4[3]

points_4d_3_4 = cv2.triangulatePoints(M3, M4, pts_img3_new_4.T, pts_img4_3.T)
points_3d_3_4 = points_4d_3_4[:3] / points_4d_3_4[3]

P_all_new_4 = np.hstack((points_3d_1_4, points_3d_2_4, points_3d_3_4))
P_total = np.hstack((P_total, P_all_new_4))

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(P_total[0], P_total[1], P_total[2], c='b', marker='o', s=1)
ax.set_title('3D Point Cloud')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
#ax.set_xlim(-0.5,0.5)
#ax.set_ylim(-0.2,0.5)
plt.show()

P_total = filter_by_depth(P_total)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(P_total[0], P_total[1], P_total[2], c='r', marker='o', s=1)
ax.set_title('3D Point Cloud')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()

kp5, des5 = sift.detectAndCompute(img5, None)

matches15 = bf.knnMatch(des5, des1, k=2)
matches25 = bf.knnMatch(des5, des2, k=2)
matches35 = bf.knnMatch(des5, des3, k=2)
matches45 = bf.knnMatch(des5, des4, k=2)


good_matches15 = [m for m, n in matches15 if m.distance < 0.8 * n.distance]
good_matches25 = [m for m, n in matches25 if m.distance < 0.8 * n.distance]
good_matches35 = [m for m, n in matches35 if m.distance < 0.8 * n.distance]
good_matches45 = [m for m, n in matches45 if m.distance < 0.8 * n.distance]

object_points = []
image_points  = []
threshold = 3

for m in good_matches15:
    pt_img1 = kp1[m.trainIdx].pt
    pt_img5 = kp5[m.queryIdx].pt

    for i, src_pt in enumerate(src_pts.reshape(-1, 2)):
        dist = np.linalg.norm(np.array(pt_img1) - src_pt)
        if dist < threshold:
            object_points.append(P[:, i])
            image_points.append(pt_img5)
            break

for m in good_matches25:
    pt_img2 = kp2[m.trainIdx].pt
    pt_img5 = kp5[m.queryIdx].pt

    for i, dst_pt in enumerate(dst_pts.reshape(-1, 2)):
        dist = np.linalg.norm(np.array(pt_img2) - dst_pt)
        if dist < threshold:
            object_points.append(P[:, i])
            image_points.append(pt_img5)
            break

existing_pts_img3 = np.vstack((pts_img3_1, pts_img3_2))
existing_pts_3d1    = np.hstack((points_3d_1, points_3d_2))

for m in good_matches35:
    pt_img3 = kp3[m.trainIdx].pt
    pt_img5 = kp5[m.queryIdx].pt

    for i, pt in enumerate(existing_pts_img3.reshape(-1, 2)):
        dist = np.linalg.norm(np.array(pt_img3) - pt)
        if dist < threshold:
            object_points.append(existing_pts_3d1[:, i])
            image_points.append(pt_img5)
            break

existing_pts_img4 = np.vstack((pts_img4_1, pts_img4_2, pts_img4_3))
existing_pts_3d1    = np.hstack((points_3d_1, points_3d_2))

for m in good_matches45:
    pt_img4 = kp4[m.trainIdx].pt
    pt_img5 = kp5[m.queryIdx].pt

    for i, pt in enumerate(existing_pts_img4):
      if i >= P_all_new.shape[1]:
          break
      dist = np.linalg.norm(np.array(pt_img4) - pt)
      if dist < threshold:
          object_points.append(P_all_new[:, i])
          image_points.append(pt_img5)
          break


object_points = np.array(object_points, dtype=np.float32).reshape(-1, 3)
image_points  = np.array(image_points, dtype=np.float32).reshape(-1, 2)

success, rvec5, tvec5 = cv2.solvePnP(object_points, image_points, K, None)
if not success:
    print("-")
else:
    R5, _ = cv2.Rodrigues(rvec5)
    M5 = K @ np.hstack((R5, tvec5))

pts_img1_new_5, pts_img5_1 = get_new_correspondences(kp1, kp5, des1, des5, src_pts.reshape(-1,2))
pts_img2_new_5, pts_img5_2 = get_new_correspondences(kp2, kp5, des2, des5, dst_pts.reshape(-1,2))
pts_img3_new_5, pts_img5_3 = get_new_correspondences(kp3, kp5, des3, des5, existing_pts_img3)
pts_img4_new_5, pts_img5_4 = get_new_correspondences(kp4, kp5, des4, des5, existing_pts_img4)


points_4d_1_5 = cv2.triangulatePoints(M1, M4, pts_img1_new_5.T, pts_img5_1.T)
points_3d_1_5 = points_4d_1_5[:3] / points_4d_1_5[3]

points_4d_2_5 = cv2.triangulatePoints(M2, M4, pts_img2_new_5.T, pts_img5_2.T)
points_3d_2_5 = points_4d_2_5[:3] / points_4d_2_5[3]

points_4d_3_5 = cv2.triangulatePoints(M3, M4, pts_img3_new_5.T, pts_img5_3.T)
points_3d_3_5 = points_4d_3_5[:3] / points_4d_3_5[3]

points_4d_4_5 = cv2.triangulatePoints(M3, M4, pts_img4_new_5.T, pts_img5_4.T)
points_3d_4_5 = points_4d_4_5[:3] / points_4d_4_5[3]


P_all_new_5 = np.hstack((points_3d_1_5, points_3d_2_5, points_3d_3_5, points_3d_4_5))
P_total = np.hstack((P_total, P_all_new_5))

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(P_total[0], P_total[1], P_total[2], c='b', marker='o', s=1)
ax.set_title('3D Point Cloud before BA')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')

plt.show()

def filter_by_depth(P_cam):
  return P_cam[:, P_cam[2, :] > 0]
P_total = filter_by_depth(P_total)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(P_total[0], P_total[1], P_total[2], c='r', marker='o', s=1)
ax.set_title('3D Point Cloud')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()
Z = P_total[2]

count_z_gt_1000     = np.sum(Z > 1000)
count_z_100_1000    = np.sum((Z > 100) & (Z <= 1000))
count_z_10_100      = np.sum((Z > 10) & (Z <= 100))
count_z_0_10        = np.sum((Z > 0) & (Z <= 10))

N_total = Z.shape[0]

print("Z > 1000       : {:.2f}%".format(100 * np.sum(Z > 1000) / N_total))
print("100 < Z <= 1000: {:.2f}%".format(100 * np.sum((Z > 100) & (Z <= 1000)) / N_total))
print("10 < Z <= 100  : {:.2f}%".format(100 * np.sum((Z > 10) & (Z <= 100)) / N_total))
print("0 < Z <= 5    : {:.2f}%".format(100 * np.sum((Z > 0) & (Z <= 5)) / N_total))
print("Z <= 0         : {:.2f}%".format(100 * np.sum(Z <= 0) / N_total))  # 훾esto su i to outlieri


z_threshold = 5.0

mask = P_total[2] < z_threshold

P_total_filtered = P_total[:, mask]
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(P_total_filtered[0], P_total_filtered[1], P_total_filtered[2], c='r', marker='o', s=1)
ax.set_title('3D Point Cloud')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()

from scipy.spatial import ConvexHull

hull = ConvexHull(P_total_filtered.T)

hull_vertices = P_total_filtered.T[hull.vertices]

import numpy as np
import cv2

def project_points(P_3d, R, tvec, K):

    P_hom = np.vstack((P_3d, np.ones((1, P_3d.shape[1]))))
    RT = np.hstack((R, tvec))
    proj = K @ (RT @ P_hom)
    proj /= proj[2, :]
    return proj[:2, :].T

def find_corresponding_keypoints(projected_pts, keypoints, des, max_dist=5):

    kp_pts = np.array([kp.pt for kp in keypoints])
    correspondences = []
    correspondences_des = []

    for pt in projected_pts:
        dists = np.linalg.norm(kp_pts - pt, axis=1)
        min_idx = np.argmin(dists)
        if dists[min_idx] < max_dist:
            correspondences.append(kp_pts[min_idx])
            correspondences_des.append(des[min_idx])
        else:
            correspondences.append(None)
            correspondences_des.append(None)

    return correspondences, correspondences_des




projected_pts_2d = project_points(P_total_filtered, R, tvec, K)

corresponding_kp_pts, corresponding_descriptors = find_corresponding_keypoints(projected_pts_2d, kp1, des1)

filtered_3d_points = []
filtered_kp_pts = []
filtered_des = []

for i, kp_pt in enumerate(corresponding_kp_pts):
    if kp_pt is not None:
        filtered_3d_points.append(P_total_filtered[:, i])
        filtered_kp_pts.append(kp_pt)
        filtered_des.append(corresponding_descriptors[i])

filtered_3d_points1 = np.array(filtered_3d_points).T  # 3xM
filtered_kp_pts1 = np.array(filtered_kp_pts)          # Mx2
filtered_des1= np.array(filtered_des)                # Mx128